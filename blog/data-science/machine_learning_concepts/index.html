<!DOCTYPE html>
<html lang="en">



<head>
    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Eunice Koid | Machine Learning Concepts</title>
    <meta name="author" content="Eunice Koid" />
    <meta name="description" content="" />
    <meta name="keywords" content="data-science, statistics" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css"
        integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Quicksand:300,400,500,700&display=swap">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css"
        integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css"
        integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css"
        media="none" id="highlight_theme_light" />

    <!-- Styles -->

    <link rel="shortcut icon"
        href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>◼️</text></svg>">

    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://eunicekoid.github.io/">

    <!-- Dark Mode -->

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css"
        media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    <style>
        body {
            margin-left: 2px;
        }

        .fixedNavigation {
            position: fixed;
            top: 1000;
            width: 275px;
            left: 10;
            padding: 10px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            font-size: 15px;
        }

        .submenu {
            margin-left: 3px;
            font-size: 11px;
        }
    </style>

</head>

<!-- Body -->

<body class="fixed-top-nav ">

    <!-- Header -->
    <header>

        <!-- Nav Bar -->
        <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
            <div class="container">
                <a class="navbar-brand title font-weight-lighter" href="https://eunicekoid.github.io/"><span
                        class="font-weight-bold">Eunice</span> Koid</a>
                <!-- Navbar Toggle -->
                <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse"
                    data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false"
                    aria-label="Toggle navigation">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar top-bar"></span>
                    <span class="icon-bar middle-bar"></span>
                    <span class="icon-bar bottom-bar"></span>
                </button>

                <div class="collapse navbar-collapse text-right" id="navbarNav">
                    <ul class="navbar-nav ml-auto flex-nowrap">

                        <!-- About -->
                        <li class="nav-item ">
                            <a class="nav-link" href="/">about</a>
                        </li>

                        <!-- Portfolio -->
                        <li class="nav-item ">
                            <a class="nav-link" href="/portfolio/">portfolio</a>
                        </li>

                        <!-- Blog -->
                        <li class="nav-item ">
                            <a class="nav-link" href="/blog/">blog</a>
                        </li>

                        <!-- Toogle theme mode -->
                        <div class="toggle-container">
                            <a id="light-toggle">
                                <i class="fas fa-moon"></i>
                                <i class="fas fa-sun"></i>
                            </a>
                        </div>
                    </ul>
                </div>
            </div>
        </nav>
    </header>



    <!-- Content -->
    <div class="container mt-5">
        <!-- page.html -->
        <div class="post">

            <header class="post-header">
                <h1 class="post-title">Machine Learning Concepts</h1>
                <p class="post-description">Click on each term to view its definition. </p>
            </header>
            <hr>


            <article>
                <style type="text/css">
                    .tg {
                        border-collapse: collapse;
                        border-spacing: 0;
                    }

                    .tg td {
                        border-color: #d3d3d3;
                        border-style: solid;
                        border-width: 1px;
                        font-size: 13px;
                        overflow: hidden;
                        padding: 5px 6px;
                        word-break: normal;
                    }

                    .tg th {
                        border-color: #d3d3d3;
                        border-style: solid;
                        border-width: 1px;
                        font-size: 13px;
                        overflow: hidden;
                        padding: 5px 6px;
                        word-break: normal;
                    }

                    .tg .tg-fymr {
                        border-color: #d3d3d3;
                        font-weight: bold;
                        text-align: left;
                        vertical-align: top
                    }

                    .tg .tg-0pky {
                        border-color: #d3d3d3;
                        text-align: left;
                        vertical-align: top
                    }
                </style>


                <!-- Button -->
                <button id="acc-button">accuracy</button>
                <p id="acc-paragraph" style="display: none;">
                    A classification model evaluation metric. \( \text{Accuracy} = \frac{\text{number of correct predictions}}{\text{total number of predictions}} \)

                    <small>(not good for imbalanced datasets)</small>
                </p>
                <script>
                    const accButton = document.getElementById('acc-button');
                    const accPara = document.getElementById('acc-paragraph');
                    accButton.addEventListener('click', () => {
                        if (accPara.style.display === 'none') {
                            accPara.style.display = 'block';
                            MathJax.typeset();
                        } else {
                            accPara.style.display = 'none';
                        }
                    });
                </script>

                <!-- Button -->
                <button id="ada-button">ada boost</button>
                <p id="ada-paragraph" style="display: none;">
                    Adaptive boosting is an ensemble method that sequentially combines decision trees with a single split and sets weights uniformly for all data points.
                    The data points are reweighted at each iteration depending on whether it was correctly classfied or not. The weighted predictions of each classifier are combined at the end to obtain a final prediction.
                </p>
                <script>
                    const adaB = document.getElementById('ada-button');
                    const adaP = document.getElementById('ada-paragraph');
                    adaB.addEventListener('click', () => {
                        if (adaP.style.display === 'none') {
                            adaP.style.display = 'block';
                            MathJax.typeset();
                        } else {
                            adaP.style.display = 'none';
                        }
                    });
                </script>


                <br />
                <br />

                <!-- Button -->
                <button id="bv-button">bias-variance tradeoff</button>
                <p id="bv-paragraph" style="display: none;">
                    Bias is how close the model's predictions are to actual data. A high bias model oversimplifies the
                    data and therefore underfits the data. <br><br>

                    Variance is the model's sensitivity to fluctuations - how much prediction error changes based on
                    training inputs. High variance models overfit the data; they tend to perform well on training set
                    but not on validation or test sets. To counter overfitting (reduce variance: <br>
                    • feature selection<br>
                    • regulatization<br>
                    • dimensionality reduction<br>
                    • subset selection (best subset selection, stepwise selection) <br><br>

                    When modeling, the tradeoff between high bias/low variance and high variance/low bias needs to be
                    balanced.
                </p>
                <script>
                    const bvB = document.getElementById('bv-button');
                    const bvP = document.getElementById('bv-paragraph');
                    bvB.addEventListener('click', () => {
                        if (bvP.style.display === 'none') {
                            bvP.style.display = 'block';
                            MathJax.typeset();
                        } else {
                            bvP.style.display = 'none';
                        }
                    });
                </script>

                <!-- Button -->
                <button id="bagging-button">bagging</button>
                <p id="bagging-paragraph" style="display: none;">
                    Short for Bootstrap Aggregating, bagging is a machine learning ensemble technique designed to
                    improve the stability and accuracy of machine learning algorithms.
                    Multiple models (often called "weak learners") are trained and combined to produce a stronger
                    overall model.
                    Multiple subsets of the original training data are created using bootstrap sampling (randomly
                    sampling with replacement).
                    A separate model is trained on each of these bootstrapped subsets. Since each subset is different,
                    each model will have slight variations.
                    Once all the models are trained, their predictions are combined. For regression tasks, this is
                    usually done by averaging the predictions. For classification tasks, it is often done by majority
                    voting.
                </p>
                <script>
                    const baggingB = document.getElementById('bagging-button');
                    const baggingP = document.getElementById('bagging-paragraph');
                    baggingB.addEventListener('click', () => {
                        if (baggingP.style.display === 'none') {
                            baggingP.style.display = 'block';
                            MathJax.typeset();
                        } else {
                            baggingP.style.display = 'none';
                        }
                    });
                </script>

                <!-- Button -->
                <button id="boosting-button">boosting</button>
                <p id="boosting-paragraph" style="display: none;">
                    Boosting is An ensemble learning technique that combines the predictions of multiple weak learners
                    (models that are slightly better than random guessing) to produce a strong learner with better
                    performance.
                    Boosting trains weak learners <i>sequentially</i> where each subsequent learner focuses on
                    addressing the mistakes of the previous model.
                </p>
                <script>
                    const boostingB = document.getElementById('boosting-button');
                    const boostingP = document.getElementById('boosting-paragraph');
                    boostingB.addEventListener('click', () => {
                        if (boostingP.style.display === 'none') {
                            boostingP.style.display = 'block';
                            MathJax.typeset();
                        } else {
                            boostingP.style.display = 'none';
                        }
                    });
                </script>

                <br />
                <br />



                <!--Button-->
                <button id="classstypes-button">classification model types</button>
                <div id="classstypes-paragraph" style="display: none; text-align: left;">
                    
                    <div style="margin: 0 auto; padding: 10px; display: inline-block;">
                        <table border=".1">
                            <tr>
                                <td><b>&nbsp;Generative Models</b></td>
                                <td><b>&nbsp;Discriminative Models</b></td>
                            </tr>
                            <tr>
                                <td>&nbsp;Joint Distribution of \(X\) and \(Y\) &nbsp;<br> &nbsp;\(P(X,Y) = P(Y|X)P(X) \)
                                </td>
                                <td>&nbsp;\( \hat{y} = argmax_k P(Y = k|x) \)&nbsp; </td>

                            </tr>

                        </table>
                        <br>
                        Determine decision boundary between classes by maximizing the posterior probability distribution. 
                    </div>
                </div>
                <script>
                    const classstypesB = document.getElementById('classstypes-button');
                    const classstypesP = document.getElementById('classstypes-paragraph');

                    classstypesB.addEventListener('click', () => {
                        if (classstypesP.style.display === 'none') {
                            classstypesP.style.display = 'block';
                        } else {
                            classstypesP.style.display = 'none';
                        }
                    });
                </script>
                <!-- Button -->
                <button id="clustering-button">clustering</button>
                <p id="clustering-paragraph" style="display: none;">
                    An unsupervised machine learning approach to group comparable data points by certain traits.
                    <br><br>

                    <b>K-means Clustering</b><br>
                    • Partitions data into <i>k</i> clusters and then arbitrarily selects centroids of those clusters
                    <br>
                    • Updates the groups by assigning points to closest cluster, updating the centroids, and then repeat
                    until convergence<br><br>

                    <b>Hierarchical Clustering</b><br>
                    • Assigns data points to clusters and adds nearest points until there's one cluster left <br>
                    • Dendogram - more interpretable <br><br>

                    <b>Density Clustering (DBSCAN)</b><br>
                    • Groups points together that have high density - have many neighbors <br>
                    • Good at detecting outliers
                </p>
                <script>
                    const clusteringB = document.getElementById('clustering-button');
                    const clusteringP = document.getElementById('clustering-paragraph');
                    clusteringB.addEventListener('click', () => {
                        if (clusteringP.style.display === 'none') {
                            clusteringP.style.display = 'block';
                        } else {
                            clusteringP.style.display = 'none';
                        }
                    });
                </script>


                <!--Button-->
                <button id="r2-button">coefficient of determination (R<sup>2</sup>)</button>
                <p id="r2-paragraph" style="display: none;">
                    R<sup>2</sup> measures how well the independent variables explain the variability in the dependent
                    variable. <br><br>

                    If R<sup>2</sup>=1, the model perfectly predicts the dependent variable. <br>
                    If R<sup>2</sup>=0, the model does not explain any variability in the dependent variable. <br><br>

                    R<sup>2</sup> = SSR (explained variance) / SST (total variance) </p>
                <script>
                    const r2Button = document.getElementById('r2-button');
                    const r2Para = document.getElementById('r2-paragraph');
                    r2Button.addEventListener('click', () => {
                        if (r2Para.style.display === 'none') {
                            r2Para.style.display = 'block';
                            MathJax.typeset();
                        } else {
                            r2Para.style.display = 'none';
                        }
                    });
                </script>


                <!--Button-->
                <button id="confusion-button">confusion matrix</button>
                <p id="confusion-paragraph" style="display: none;">
                    <img class="img-fluid z-dept-1" src="images/confusion_matrix.png" alt="confusion_matrix.png"
                        style="width: 90%;" />

                </p>
                <script>
                    const confusionButton = document.getElementById('confusion-button');
                    const confusionParagraph = document.getElementById('confusion-paragraph');

                    confusionButton.addEventListener('click', () => {
                        if (confusionParagraph.style.display === 'none') {
                            confusionParagraph.style.display = 'block';
                        } else {
                            confusionParagraph.style.display = 'none';
                        }
                    });
                </script>

                <!--Button-->
                <button id="cook-button">cook's distance</button>
                <p id="cook-paragraph" style="display: none;">
                    Estimates the influence of any given data point. Considers residual and leverage (how far the point
                    difference from other X values). A method to identify outliers; remove points beyond a certain
                    threshold
                </p>
                <script>
                    const cookB = document.getElementById('cook-button');
                    const cookP = document.getElementById('cook-paragraph');

                    cookB.addEventListener('click', () => {
                        if (cookP.style.display === 'none') {
                            cookP.style.display = 'block';
                        } else {
                            cookP.style.display = 'none';
                        }
                    });
                </script>


                <!--Button-->
                <button id="cv-button">cross validation</button>
                <p id="cv-paragraph" style="display: none;">
                    Cross validation is a method of splitting the data into training and test subsets to avoid testing
                    and training on the same data. Doing so may cause overfitting which decrease the model's
                    performance. <br><br>

                    <b>k-fold cross validation</b><br>
                    1. Randomly divide the data into <i>folds</i> of equal size <br>
                    2. Train the model on all folds except for one, which is the validation set on which the model is
                    evaluated. <br>
                    &nbsp; &nbsp; For each training run, change the validation fold. <br>
                    3. Average the <i>k</i> validation errors to get an estimate of the true error.
                    <br><br>

                    <b>leave one out corss validation (LOOCV)</b> <br>
                    A special case of k-fold cross validation where <i>k</i> equals the size of the dataset (<i>n</i>). The model tests every single data point during cross validation. Computationally expensive.

                </p>
                <script>
                    const cvB = document.getElementById('cv-button');
                    const cvP = document.getElementById('cv-paragraph');

                    cvB.addEventListener('click', () => {
                        if (cvP.style.display === 'none') {
                            cvP.style.display = 'block';
                        } else {
                            cvP.style.display = 'none';
                        }
                    });
                </script>
                <br />
                <br />

                <!--Button-->
                <button id="decisiontree-button">decision trees</button>
                <p id="decisiontree-paragraph" style="display: none;"> A supervised machine learning model that can be
                    used for classification or regression problems. The algorithm is trained in a greedy and recursive
                    fashion starting at a root node and making binary splits in features that lead to minimal error.
                </p>
                <script>
                    const decisiontreeB = document.getElementById('decisiontree-button');
                    const decisiontreeP = document.getElementById('decisiontree-paragraph');

                    decisiontreeB.addEventListener('click', () => {
                        if (decisiontreeP.style.display === 'none') {
                            decisiontreeP.style.display = 'block';
                        } else {
                            decisiontreeP.style.display = 'none';
                        }
                    });
                </script>

                <br />
                <br />

                <!--Button-->
                <button id="entropy-button">entropy</button>
                <p id="entropy-paragraph" style="display: none;"> Quantifies uncertainty in a random variable assuming \(k\) states <br>
                    Entropy \(H(Y) = \sum_{i=1}^k P(Y = k) log(PY=k)\) <br>
                    Higher entropy means closer to uniform distribution than a skewed one.<br><br>
                    Example: Gini index
                </p>
                <script>
                    const entropyB = document.getElementById('entropy-button');
                    const entropyP = document.getElementById('entropy-paragraph');

                    entropyB.addEventListener('click', () => {
                        if (entropyP.style.display === 'none') {
                            entropyP.style.display = 'block';
                        } else {
                            entropyP.style.display = 'none';
                        }
                    });
                </script>

                <br />
                <br />



                <!--Button-->
                <button id="f1-button">F1 score</button>
                <p id="f1-paragraph" style="display: none;">A classification model evaluation metric, good for
                    imbalanced datasets>
                    \[ F_1 = 2 \times \frac{\text{precision} \times \text{recall}}{\text{precision} + \text{recall}} \]
                    Optimize for the F1 score to balance precision vs. recall.
                </p>
                <script>
                    const f1Button = document.getElementById('f1-button');
                    const f1Paragraph = document.getElementById('f1-paragraph');

                    f1Button.addEventListener('click', () => {
                        if (f1Paragraph.style.display === 'none') {
                            f1Paragraph.style.display = 'block';
                        } else {
                            f1Paragraph.style.display = 'none';
                        }
                    });
                </script>

                <br />
                <br />

                <!--Button-->
                <button id="glm-button">generalized linear models (GLM)</button>
                <p id="glm-paragraph" style="display: none;">Linear regression that allows residuals to not be normally distributed
                <br>
                <img class="img-fluid z-dept-1" src="images/glm.png" alt="glm.png" style="width: 70%;" />

                </p>
                <script>
                    const glmB = document.getElementById('glm-button');
                    const glmP = document.getElementById('glm-paragraph');

                    glmB.addEventListener('click', () => {
                        if (glmP.style.display === 'none') {
                            glmP.style.display = 'block';
                        } else {
                            glmP.style.display = 'none';
                        }
                    });
                </script>

                <br />
                <br />


                <!--Button-->
                <button id="ig-button">information gain</button>
                <p id="ig-paragraph" style="display: none;"> In a decision tree, maximize IG recursively on all branches
                    <br>
                    For some feature \(X\) on which we want to split, \( IG(X,Y) = H(Y) - H(Y|X)\) <br>
                    \(IG(X,Y)\) is the reduction in uncertainty in \(Y\) by splitting on \(X\)<br>
                    \(H(Y)\) is the entropy from initial training labels
                </p>
                <script>
                    const igB = document.getElementById('ig-button');
                    const igP = document.getElementById('ig-paragraph');

                    igB.addEventListener('click', () => {
                        if (igP.style.display === 'none') {
                            igP.style.display = 'block';
                        } else {
                            igP.style.display = 'none';
                        }
                    });
                </script>

                <br />
                <br />

                <!--Button-->
                <button id="lime-button">LIME</button>
                <p id="lime-paragraph" style="display: none;"> Local Interpretable Model-Agnostic Explanation <br><br>
                    Uses sparse linear models built around various predictions to understand how any model performs in
                    that local vicinity.
                </p>
                <script>
                    const limeB = document.getElementById('lime-button');
                    const limeP = document.getElementById('lime-paragraph');

                    limeB.addEventListener('click', () => {
                        if (limeP.style.display === 'none') {
                            limeP.style.display = 'block';
                        } else {
                            limeP.style.display = 'none';
                        }
                    });
                </script>

                <!--Button-->
                <button id="logreg-button">logistic regression</button>
                <p id="logreg-paragraph" style="display: none;"> 
                    A supervised machine learning algorithm for binary classification.
                    It predicts the likelihood of a binary outcome based on input variables using a logistic (sigmoid) function to map linear outputs to probabilities. <br>
                    Sigmoid \( S(x) = \frac{1}{1+e^{-x \beta}} \) <br>
                    &nbsp; where \(x\) are predictor variables <br>
                    &nbsp; and \(\beta\) is a vector of weights <br>
                    <br>
                    \(P (\hat{Y} = 1|X) = S(X \beta) \)

                    <br><br>
                    Pros: <br>
                    &nbsp; • high explainability <br>
                    &nbsp; • quick to compute
                    <br><br>
                    Cons: <br>
                    &nbsp; • high bias, low variance (prone to underfit, assumes linear boundary layer) <br>
                    &nbsp; • weights, \(\beta \) terms, are not accurate if input variables are correlated
                </p>
                <script>
                    const logregB = document.getElementById('logreg-button');
                    const logregP = document.getElementById('logreg-paragraph');

                    logregB.addEventListener('click', () => {
                        if (logregP.style.display === 'none') {
                            logregP.style.display = 'block';
                        } else {
                            logregP.style.display = 'none';
                        }
                    });
                </script>

                <br />
                <br />


                <!--Button-->
                <button id="mae-button">mean absolute error (MAE)</button>
                <p id="mae-paragraph" style="display: none;">
                    Evaluation metric for regression that measures the average
                    absolute difference between the actual and predicted values. Lower MAE means better model
                    performance.
                    \[ MAE = \frac{1}{n} \sum_{i=1}^{n} \mid y_i - \hat{y}_i \mid \]
                </p>
                <script>
                    const maeButton = document.getElementById('mae-button');
                    const maePara = document.getElementById('mae-paragraph');
                    maeButton.addEventListener('click', () => {
                        if (maePara.style.display === 'none') {
                            maePara.style.display = 'block';
                            // Trigger MathJax typesetting after displaying the equation
                            MathJax.typeset();
                        } else {
                            maePara.style.display = 'none';
                        }
                    });
                </script>


                <!--Button-->
                <button id="mse-button">mean squared error (MSE)</button>
                <p id="mse-paragraph" style="display: none;">
                    Evaluation metric for regression that measures the average of the squared differences between
                    actual and predicted values. Lower MSE means better model performance. The MSE represents
                    unexplained
                    variance, the portion of variability in the dependent variable that is not explained by the
                    model's independent variables.
                    \[ MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 \]
                </p>
                <script>
                    const mseButton = document.getElementById('mse-button');
                    const msePara = document.getElementById('mse-paragraph');
                    mseButton.addEventListener('click', () => {
                        if (msePara.style.display === 'none') {
                            msePara.style.display = 'block';
                            MathJax.typeset();
                        } else {
                            msePara.style.display = 'none';
                        }
                    });
                </script>

                <!--Button-->
                <button id="multicollinearity-button">multicollinearity</button>
                <p id="multicollinearity-paragraph" style="display: none;">
                    When predictors are highly correlated with each other so it's hard to distinguish the true
                    underlying weights. <br><br>
                    Multicollinearity can be assessed with the Variance Inflation Factor (VIF). It quantifies how much
                    the estimated coefficients are inflated when multicollinearity exists. A VIF of 1 means there is no
                    correlated. >1 means there is correlation. 5-10 means there is high multicollinearity. <br><br>
                    Multicollinearity can be removed by: <br>
                    • removing correlated variables<br>
                    • linearly combine variables<br>
                    • PCA (dimensionality reduction)<br>
                    • PLS (partial least squares) <br>
                    • regularization methods (ridge or lasso)
                </p>
                <script>
                    const multicollinearityB = document.getElementById('multicollinearity-button');
                    const multicollinearityP = document.getElementById('multicollinearity-paragraph');
                    multicollinearityB.addEventListener('click', () => {
                        if (multicollinearityP.style.display === 'none') {
                            multicollinearityP.style.display = 'block';
                            MathJax.typeset();
                        } else {
                            multicollinearityP.style.display = 'none';
                        }
                    });
                </script>

                <br />
                <br />


                <!--Button-->
                <button id="naive-button">naive bayes</button>
                <p id="naive-paragraph" style="display: none;">
                    A supervised machine learning algorithm used for classification problems that applies Bayes' Theorem with a naive assumption of independence between features.
                    In other words, it decouples the class conditional feature distributions by assuming that the presence of a particular feature in a class is independent of all other features. Each feature's distribution can be independently estimated as a 1-D distribution \( P(X_1...X_n|Y)=\prod_{i=1}^n P(X_i|Y) \). Apply the conditional independence assumption and Bayes' Theorem gives the classification rule \( \hat{y}=argmax_{y_i} P(Y=y_i)\prod^j P(X_j|Y=y_i)\). 
                    <br><br>
                    For any machine learning model with <i>k</i> features, there are 2\(^k\) possible feature interactions. You would need that many data points for a good model. However, the conditional independence assumption of Naive Bayes requires only <i>k</i> data points. 

                    
                </p>
                <script>
                    const naiveB = document.getElementById('naive-button');
                    const naiveP = document.getElementById('naive-paragraph');
                    naiveB.addEventListener('click', () => {
                        if (naiveP.style.display === 'none') {
                            naiveP.style.display = 'block';
                            MathJax.typeset();
                        } else {
                            naiveP.style.display = 'none';
                        }
                    });
                </script>

                <br />
                <br />

                <!-- Button -->
                <button id="precision-button">precision</button>
                <p id="precision-paragraph" style="display: none;">
                    A classification model evaluation metric. \( \text{Precision} = \frac{\text{# true
                    positives}}{\text{(# true positives + # false positives)}} \)
                    <br>tradeoff with Recall


                </p>
                <script>
                    const precisionButton = document.getElementById('precision-button');
                    const precisionPara = document.getElementById('precision-paragraph');
                    precisionButton.addEventListener('click', () => {
                        if (precisionPara.style.display === 'none') {
                            precisionPara.style.display = 'block';
                            MathJax.typeset();
                        } else {
                            precisionPara.style.display = 'none';
                        }
                    });
                </script>
                <br />
                <br />


                <!--Button-->
                <button id="rf-button">random forest</button>
                <p id="rf-paragraph" style="display: none;">
                    Random forest is an ensemble bagging method that averages decision trees. A random subset of
                    features is considered for each split. Its advantages are that it helps overcome decision trees'
                    proneness to overfitting, has quicker training time, and more interpretable.
                </p>
                <script>
                    const rfB = document.getElementById('rf-button');
                    const rfP = document.getElementById('rf-paragraph');
                    rfB.addEventListener('click', () => {
                        if (rfP.style.display === 'none') {
                            rfP.style.display = 'block';
                        } else {
                            rfP.style.display = 'none';
                        }
                    });
                </script>

                <!--Button-->
                <button id="reg-button">regression</button>
                <p id="reg-paragraph" style="display: none;">A technique for quantifying the relationship
                    between independent variables (features or predictors) and a dependent variable (target or outcome)
                    to make predictions and illuminate the influence of the independent variables on the target.
                    <br />
                    <br />
                    <b>Multiple Regression</b>: Two or more independent variables to predict one dependent variable
                    <br />
                    <b>Linear Regression</b>: The relationship between the independent and dependent
                    variables are fitted with a linear equation <br />
                    <b>Polynominal Regression</b>: The relationship between the independent and
                    dependent variables are fitted with a polynomial equation such as quadratic or cubic <br />
                    <b>Ridge and Lasso Regression</b>: Regularization technique to handle collinearity (high
                    correlation
                    among features) to prevent overfitting. It introduces additional information to penalize extreme
                    parameter (weight) values
                </p>
                <script>
                    const regButton = document.getElementById('reg-button');
                    const regParagraph = document.getElementById('reg-paragraph');
                    regButton.addEventListener('click', () => {
                        if (regParagraph.style.display === 'none') {
                            regParagraph.style.display = 'block';
                        } else {
                            regParagraph.style.display = 'none';
                        }
                    });
                </script>

                <!--Button-->
                <button id="rss-button">residual sum of squares</button>
                <p id="rss-paragraph" style="display: none;">Unexplained variance from a model. For example, in a linear
                    regression, parameter \(\beta\) is found by minimizing RSS. Also known as Sum of Square Errors
                    (SSE). <br>
                    \(RSS(\beta) = (y - X\beta)^T(y-X\beta) \)
                </p>
                <script>
                    const rssB = document.getElementById('rss-button');
                    const rssP = document.getElementById('rss-paragraph');
                    rssB.addEventListener('click', () => {
                        if (rssP.style.display === 'none') {
                            rssP.style.display = 'block';
                        } else {
                            rssP.style.display = 'none';
                        }
                    });
                </script>

                <!--Button-->
                <button id="rocauc-button">ROC curve & AUC</button>
                <p id="rocauc-paragraph" style="display: none;">
                    The receiver operating characteristic (ROC) curve shows a classification model's performance across
                    all classification thresholds. The area under the curve (AUC) is the area under the ROC. An AUC of 1
                    means the model performed perfectly. An AUC of 0.5 means that the model performed as well as random
                    guessing.
                    <img class="img-fluid z-dept-1" src="images/roc_auc.png" alt="roc_auc.png" style="width: 90%;" />

                </p>
                <script>
                    const rocaucButton = document.getElementById('rocauc-button');
                    const rocaucParagraph = document.getElementById('rocauc-paragraph');

                    rocaucButton.addEventListener('click', () => {
                        if (rocaucParagraph.style.display === 'none') {
                            rocaucParagraph.style.display = 'block';
                        } else {
                            rocaucParagraph.style.display = 'none';
                        }
                    });
                </script>

                <!--Button-->
                <button id="rmse-button">root mean squared error (RMSE)</button>
                <p id="rmse-paragraph" style="display: none;">The square root of MSE. This metric helps with:
                    <br><br>
                    <b>Interpretability</b>: Because RMSE is expressed in the same unit as the dependent variable,
                    it is easier
                    to interpret and more relatable to the original scale of the data.<br><br>

                    <b>Outlier Sensitivity</b>: RMSE is more sensitive to outliers than MSE, as larger errors
                    contribute more
                    significantly due to the squared and square root operations.<br><br>

                    <b>Direct Comparison</b>: RMSE offers a direct comparison to the standard deviation of the
                    target.
                    If the
                    RMSE is close to the standard deviation (the inherent variability in the original data), then it
                    indicates that the model's predictions are capturing a similar level of variability on average
                    as
                    the observed data. <br><br>

                    <b>Balanced Assessment</b>: By taking the square root, RMSE balances the impact of extreme
                    errors,
                    offering
                    a more well-rounded evaluation of prediction accuracy in regression models.
                </p>
                <script>
                    const rmse_Button = document.getElementById('rmse-button');
                    const rmse_Paragraph = document.getElementById('rmse-paragraph');
                    rmse_Button.addEventListener('click', () => {
                        if (rmse_Paragraph.style.display === 'none') {
                            rmse_Paragraph.style.display = 'block';
                        } else {
                            rmse_Paragraph.style.display = 'none';
                        }
                    });
                </script>
                <br />
                <br />


                <!--Button-->
                <button id="sensitivity-button">sensitivity</button>
                <p id="sensitivity-paragraph" style="display: none;">A classification model evaluation metric also known
                    as <i>recall</i> or the <i>true positive rate</i>. \( \text{Sensitivity} = \frac{\text{# true
                    positives}}{\text{(# true positives + # false negatives)}} \)
                </p>
                <script>
                    const sensitivityButton = document.getElementById('sensitivity-button');
                    const sensitivityParagraph = document.getElementById('sensitivity-paragraph');
                    sensitivityButton.addEventListener('click', () => {
                        if (sensitivityParagraph.style.display === 'none') {
                            sensitivityParagraph.style.display = 'block';
                        } else {
                            sensitivityParagraph.style.display = 'none';
                        }
                    });
                </script>


                <!--Button-->
                <button id="specificity-button">specificity</button>
                <p id="specificity-paragraph" style="display: none;">A classification model evaluation metric. \(
                    \text{Specificity} = \frac{\text{# false positives}}{\text{(# false positives + # true negatives)}}
                    \)
                </p>
                <script>
                    const specificityButton = document.getElementById('specificity-button');
                    const specificityParagraph = document.getElementById('specificity-paragraph');
                    specificityButton.addEventListener('click', () => {
                        if (specificityParagraph.style.display === 'none') {
                            specificityParagraph.style.display = 'block';
                        } else {
                            specificityParagraph.style.display = 'none';
                        }
                    });
                </script>

                <!--Button-->
                <button id="sst-button">SST (total sum of squares)</button>
                <p id="sst-paragraph" style="display: none;">The sum of the squared differences between each
                    observation
                    and the mean of the dependent variable \( \hat{y} \).
                    <img class="img-fluid z-dept-1" src="images/sst.jpg" alt="sst.jpg" style="width: 70%;" />
                </p>
                <script>
                    const sstButton = document.getElementById('sst-button');
                    const sstParagraph = document.getElementById('sst-paragraph');

                    sstButton.addEventListener('click', () => {
                        if (sstParagraph.style.display === 'none') {
                            sstParagraph.style.display = 'block';
                        } else {
                            sstParagraph.style.display = 'none';
                        }
                    });
                </script>

                <!--Button-->
                <button id="selection-button">subset selection</button>
                <p id="selection-paragraph" style="display: none;">
                    Stepwise Selection <br>
                    &nbsp; • <b>Forward</b>: Start with an empty model and add the most useful predictors iteratively
                    <br>
                    &nbsp; • <b>Backward</b>: Start with a full model and remove least useful predictors iteratively
                </p>
                <script>
                    const selectionB = document.getElementById('selection-button');
                    const selectionP = document.getElementById('selection-paragraph');

                    selectionB.addEventListener('click', () => {
                        if (selectionP.style.display === 'none') {
                            selectionP.style.display = 'block';
                        } else {
                            selectionP.style.display = 'none';
                        }
                    });
                </script>

                <!--Button-->
                <button id="svm-button">support vector machines</button>
                <p id="svm-paragraph" style="display: none;">
                    A max-margin supervised classification model that forms a hyperplane that linearly separates the
                    training data. The margin between the decision boundary (hyperplane) to any training point (usually
                    the support vectors) is maximized. The margin can be linear or nonlinear. <br><br>

                    SVM works well: <br>
                    • for high dimensional spaces<br>
                    • when there is a clear hyperplane <br>
                    • for nonlinear decision boundary <br><br>

                    SVM does not work well: <br>
                    • on large datasets (high computational complexity)<br>
                    • when target classes overlap (no clear decision boundaries)<br>
                    • SVM is also hard to interpret/explain and is sensitive to outliers

                </p>
                <script>
                    const svmB = document.getElementById('svm-button');
                    const svmP = document.getElementById('svm-paragraph');

                    svmB.addEventListener('click', () => {
                        if (svmP.style.display === 'none') {
                            svmP.style.display = 'block';
                        } else {
                            svmP.style.display = 'none';
                        }
                    });
                </script>



                <br />
                <!-- <hr> -->
                <!-- Adds related posts to the end of an article -->
                <!-- <h3 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h3>
                <p class="mb-2">Here are some more articles you might like to read next:</p>
                <li class="my-2"> -->
                <!-- <a class="text-gray-700 underline font-semibold hover:text-gray-800" href="/blog/2022/displaying-external-posts-on-your-al-folio-blog/">Displaying External Posts on Your al-folio Blog</a> -->
                </li>

            </article>
        </div>
    </div>

    <!-- Footer -->
    <footer class="fixed-bottom">
        <div class="container mt-0">
            <!-- © Copyright 2022 Eunice Koid. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. -->

        </div>
    </footer>

    <!-- JavaScripts -->
    <script>
        function toggleNavigation() {
            var navigation = document.querySelector('.fixedNavigation');
            if (window.innerWidth <= 1400) {
                navigation.style.display = 'none';
            } else {
                navigation.style.display = 'block';
            }
        }

        // Initial call to set the initial state on page load
        toggleNavigation();

        // Attach the function to the resize event
        window.addEventListener('resize', toggleNavigation);
    </script>

    <!-- jQuery -->
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"
        integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js"
        integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js"
        integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js"
        integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
    <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js"
        integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
    <script defer src="/assets/js/masonry.js" type="text/javascript"></script>

    <!-- Medium Zoom JS -->
    <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js"
        integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
    <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
    <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
    <script type="text/javascript">
        window.MathJax = {
            tex: {
                tags: 'ams'
            }
        };
    </script>
    <script defer type="text/javascript" id="MathJax-script"
        src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
    <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


</body>

</html>